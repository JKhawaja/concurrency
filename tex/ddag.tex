\section{Dependency DDAGs}

We begin our discussion around the crux of avoiding undesirable behavior: \textit{Ordering} (in the literature: \textit{linearization}).

In our definition of a CDS (\ref{cds}), we discussed reading and writing data to a structure as well as changing the structure of the CDS itself. We will label all of these processes as: \textit{access types}. More specifically: these are procedural types. Every time we try to execute an access type we will call this an: \textit{access procedure}.

We do not want to limit ourselves to some pre-defined set of operations such as ``reads, writes, appends, removals, etc.''. These do represent a sort of canonical basis for all possible access types, but we want to be flexible enough to allow for any and all possible methods of accessing a CDS.

Thus, we need to find a way to ensure the linearization, or correct ordering, of access procedures. 

For example, when and how will we guarantee that one access procedure completes before another one is started? The how is simple: we can sequentially order our access procedures i.e. apply a total ordering to all access procedures across our system. 

But that can be accomplished by using only a single process without the necessity for concurrent processes. Thus we need to address the \textit{when} of ordering access procedures using multiple concurrent processes.

Not all access procedures will need to be totally-ordered i.e. a complete (mathematical) linearization of our access procedures is not always a necessity. It is this \textit{lack of necessity of a total ordering} that allows us to have the possibility of concurrency in the first place. 

The degree to which our system can behave non-linearly is exactly the minimal degree to which it can be composed of concurrent processes. (Note: by "system" we are referring to a set of processes plus our CDS).

So, when is ordering a necessity? The only time two access procedures need an order is if one access procedure is \textit{dependent} on the other. We do not specify the reason for the dependency, but if a dependency exists (at all) then it is easy to see that an ordering is necessary.

Since the necessity for an ordering is not always required, we see that a complete linearization of our system is not always a necessity. Rather, the access procedures which carry a dependency on other access procedures create a \textit{partial ordering} for our system.

More specifically: all of our dependencies allows us to have a (disjoint )\textit{dependency graph} for our access procedures.

All good, right?! Sort of. Sadly, this does not resolve all of our problems. We have not discussed exactly how we will order access procedures in terms of processes.

\subsection{Spatial Dependencies}

First, let's diverge quickly back into a discussion of our CDS. Let's try to formalize it:

\begin{con-def}[Concurrent Data Structure (2)]
	\label{cds-graph}
	A \textit{concurrent data structure} is a graph $\mathcal{G} = \{\mathsf{N}, \mathsf{E}\}$ composed of $|\mathsf{N}|$ nodes and $|\mathsf{E}|$ edges, that is used to index data of type $\mathcal{T}$, and is allowed to be accessed by some set of processes $\mathcal{P}_{i}$ via some set of access types $\mathcal{A}_{t}$.
\end{con-def}

This helps us to remember that a data structure is a spatial object. It carries a certain topology and is invariant through time unless modified. Thus, it is completely possible that while access procedures may not carry a dependency: nodes of our CDS just might! The set of all nodular-dependencies will be called the: \textit{set of spatial dependencies}. These dependencies may be the dependencies that an access procedure ``adopts'' in order to consider itself dependent on another access procedure.

For example: if access procedure $\mathit{A}$ is trying to write to node $\mathrm{n}_{1} \in \mathsf{N}$ and access procedure $\mathit{B}$ is trying to write to node $\mathrm{n}_{2} \in \mathsf{N}$, but $\mathrm{n}_{2} < \mathrm{n}_{1}$ (where $<$ is a dependency arrow), then we would want to perform $\mathit{B}$ before $\mathit{A}$.

This set of spatial dependencies only covers the dependency relationships between certain nodes in our graph. But what if we wanted sub-graphs of our CDS to be dependent or more importantly \textit{independent} of other sub-graphs of our CDS?

Let's define this:

\begin{con-def}[Unique-Independent]
	\label{independents}
	Any sub-graph $\mathcal{S} \subseteq \mathcal{G}$ that does not contain any internal spatial dependencies is called an \textit{unique-independent} of our CDS.
\end{con-def}

Unique-Independents (UIs) can almost be seen as a \textit{virtualization} of our CDS's spatial topology.

Unique-Independents can obviously have external dependencies i.e. be dependent on each other. Thus, the set of UIs of our CDS forms a dependency graph. Although, since UIs do not have to have other UIs as dependencies, we simply qualify this as a: dependencies list.

\begin{con-def}[Dependency List]
	\label{dependency-list}
	A \textit{dependencies list} for a CDS is the adjacency list of our disjointed graph of unique-independents.
\end{con-def}

\if
For any algebraist reading this: our dependencies list can almost be considered an \textit{anti-group} since inverses of ordered pairs \textit{cannot} exist in our list. An identity element cannot exist as the composition of any two objects cannot return to itself as that implies a cyclic dependency. Associativity and closure can exist for a basic composition operation, but objects in our dependency list can only be composed functionally (i.e. the last element of the ordered pair must be the first element of the ordered pair it is being composed with) -- so this composition only applies to a subset of our dependencies list. Thus, our dependencies list really becomes a sort of quasi-antithesis to a group.
\fi

Don't let the name ``unique-independent'' fool you. There is no requirement for an independent to be spatially-unique. In other words, a UI can share nodes from the CDS with other UIs. The only thing that makes a unique-independent ``unique'' is that it is in totality unique as to the nodes it applies too. 

So while, a unique-independent can be completely subsumed by another unique-independent spatially, it will never refer to the exact same set of nodes that another unique-independent is referring too. And it is this notion of ``uniqueness'' that allows it to be an independent.

This may seem like a unique-independent that subsumes UIs with dependencies that are other subsumed UIs conflicts with our definition (\ref{independents}) of an unique-independent. 

However, what we have to notice is that a unique-independent is evaluated separately from other UIs i.e. a UI that subsumes other UIs and their dependencies is only allowed to be addressed after all those other UIs have been addressed.

So, while an independent has ``no spatial dependencies'' it can still subsume UI-dependencies. 

One of the most important points to take away from this section is the fact that: the structure of the CDS itself has zero semblance of how we design our concurrent accesses, only the structure of our UI-DDAG (disjoint directed acyclic graph) does.

\subsection{Temporal Dependencies}

Now that we have a way to virtualize a CDS using UIs (in a spatial manner), let's tie UIs back in with our previous discussion about ordering access procedures.

We can now use the UI (spatial) virtualization of our CDS to assign an access procedure to a particular UI. More precisely, we want an access procedure to be composed of an access type and a UI assignment. 

We can provide a brief pseudo-code example written in the Go programming language syntax.

\begin{minted}{go}
type AccessProcedure struct{
	A AccessType
	UID int // unique-independent id
}
\end{minted}

Since our dependency list of UIs based off this virtualization represents all possible spatial dependencies in our CDS it can be used to help us apply an ordering to access procedures. However, a spatial dependency is not the only way access procedures can be ordered i.e. be dependent on each other. The other way access procedures can have is an ordering: is \textit{per UI}.

In other words, we can still order all access procedures that have been assigned to the same UI. For example, will read access procedures always take precedence over write access procedures for a particular UI? What if we wanted to be more specific (fine-grained) than that and give \textit{certain} access procedures precedence over \textit{certain} write access procedures?

It would be impossible to suggest that access procedures that apply to a specific UI could always be totally-ordered. Thus, we arrive at the same situation we were in before with trying to linearize our system. Thankfully, we have the answer: a dependency graph (list). Except, this time our dependencies list are access procedures assigned to the same UI. 

Whereas we had an UIs dependency list that represented a virtualization of the spatial dependencies, we now have a procedures dependency list that virtualizes the temporal dependencies of our CDS (per UI). Every UI will have it's own temporal dependencies list and every node in this disjoint dependencies graph will be a specific access procedure.

\subsection{Atomicity}

We still have to come back around to combining our ordering of dependencies with the processes in our system. But, first we should consider when two access procedures can be simply sequentially ordered. If some set of access procedures which apply to the same UI must be linearly ordered then we can consider the sequence of those procedures as being a new access procedure.

This can technically also apply to any sequence of access procedures (assigned to the same UI) that are not dependent on one another. If we want to reduce the total number of individual procedures in our system (i.e. reduce the number of nodes in our temporal dependency graph for a UI) then we can combine access procedures that are either linearly dependent or independent into a single access procedure.

The allowance for this combination is what we call: \textit{atomicity}. Every access procedure must be \textit{atomic}.

\begin{con-def}[Atomic Procedures]
	\label{atomic-procedures}
	Any access procedure or sequence of procedures that appear to the rest of the system as a single operation on a UI are called: \textit{atomic procedures}.
\end{con-def}

All access procedures \textit{should be} atomic procedures. But, arbitrary sequences of procedures are not necessarily atomic. We want to specifically classify sequences of access procedures that are atomic.

\begin{con-def}[Thread]
	\label{thread}
	A \textit{thread} is any sequence of access procedures that can be classified as an atomic procedure. In terms of a dependency graph: a thread is assigned to a node and is also assigned to the node's dependencies iff the dependent node has only one dependency \textit{and} the dependency has only one dependent. Any sequence of nodes each with at most one dependency and one dependent can be "combined" and considered: a single Thread.
\end{con-def}

Using threads makes our virtualization complexes more succinct, as any and all sequences of access procedures are either necessarily ordered or are considered single atomic procedures. It also becomes that every node in our disjoint dependency graphs are now a thread.

\begin{props}[Nodes are Threads]
	\label{nodes-are-threads}
	Every node in our disjoint temporal dependency graphs is a thread (iff we maintain that all access procedures must be atomic procedures).
\end{props}

\begin{con-cor}[Thread DDAG]
	\label{thread-ddag}
	For every disjoint dependency graph (a disjoint directed acyclic graph i.e. DDAG) of access procedures there is an equivalent disjoint dependency graph of threads.
\end{con-cor}

In the next section of this paper we will discuss how we will ensure atomicity for access procedures. But, for now, we simply hold this assumption as a given precondition.

\subsection{Dynamic Dependencies}

Now that we have methods for defining both spatial and temporal dependencies in our system, the question arises: what happens if a dependency has a lifecycle? What if a dependency needs to only hold true some of the time?

To solve these dynamic situations we can introduce the idea of a \textit{Virtual Dependency Graph} (VDG) which is a dependency graph that can apply to multiple UIs. The key is that is \textit{must} have a limited lifespan. If it does not have a limited lifespan then it just becomes another spatial or temporal DDAG.

\begin{con-def}[Virtual DDAG]
	\label{thread}
	A dependency disjoint directed acyclic graph that can apply to one or more UIs for our CDS, but whose lifespan must be less than the lifespan of the CDS (system). Used to define dynamic dependencies in a concurrent system.
\end{con-def}

A VDG will always have a root node that connects to each UI that the VDG involves. This root node represents the final atomic procedure that the VDG will finish before completing its lifecycle.

For example, what if a particular write on one UI needed to happen before a different write on another UI, but that this was \textit{not} necessarily true for \textit{all} writes for these two UIs?

The final write would be the VDG's root node, and the dependency write would be a single child node to the root node. This also means that the two nodes could be a single thread that sequentially ordered a write to the first UI then a write to the second.

So, VDGs can be assigned to a single UI or too multiple UIs. 

But, \textit{why} exactly must a VDG always have a limited lifespan (relative to the lifecycle of the system)? 

Well, in our previous mentioned example, if that VDG that applied to two UIs lasted forever then it would be no different than a spatial dependency (since it would signify that all writes for the dependent UI must wait on all writes for the dependency UI). If the VDG had only applied to a single UI then it would become a permanent temporal DDAG for similiar reasons. The only thing that makes a VDG dynamic is the fact that it's lifespan is always less then that of the CDS.

CAN A THREAD BE ASSIGNED TO MULTIPLE V-DDAGs?

WHAT IF WE WANTED UIs TO BE DYNAMIC?? CAN A UI HAVE A LIFECYCLE?

\subsection{Invariance}

The final part of discussing disjoint directed acyclic graphs and their equivalent dependencies lists is determining if an access type is allowed or not allowed to be used on a specific UI (or even at a specific time).

Boundary Nodes on our UI dependency graph are useful for determining what access types are allowed for a UI.

\begin{con-def}[Boundaries]
	\label{boundaries}
\end{con-def}

\begin{con-ex} [2-Regular Tree]
	\label{2-regular-tree}

	We consider boundary nodes of a UI dependency graph for a 2-Regular Tree CDS.

\end{con-ex}

In Example \ref{2-regular-tree}, we see that modifying the structure of our tree is dependent on what we want to preserve. Thus, we do not allow UIs with dependencies to have the ability to use access types that modify our CDS structure. But, we could if we wanted too. Thus, each UI could be assigned a list of \textit{immutables}. More specifically, a list of nodes in the CDS that are \textit{invariant} to certain access types.

Note: immutability is only a kind of invariance. A low-resolution invariance which blanket-denies all modification access types i.e. leaves the value of the data invariant under access procedures that are of a value modifier access type.

\subsection{Review}

Spatial Dependencies are dependency definitions that last the lifespan of the CDS and apply to all access types (and threads) that are assigned to the UIs involved in the dependency relationship.

Temporal Dependencies are dependency definitions that last the lifespan of the UI and apply to a specific access procedure that is assigned to a single UI.

Virtual Dependencies are dependency definitions that have a lifespan shorter than the CDS (or UI that they are assigned to) and can be assigned to multiple UIs.




