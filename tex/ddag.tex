\section{Dependency DDAGs}

We begin our discussion around the crux of avoiding undesirable behavior: \textit{Ordering} (in the literature: \textit{linearization}).

In our definition of a CDS (\ref{cds}), we discussed reading and writing data to a structure as well as changing the structure of the CDS itself. We will label all of these processes as: \textit{access types}. More specifically: these are procedural types. Every time we try to execute an access type we will call this an: \textit{access procedure}.

We do not want to limit ourselves to some pre-defined set of operations such as ``reads, writes, appends, removals, etc.''. These do represent a sort of canonical basis for all possible access types, but we want to be flexible enough to allow for any and all possible methods of accessing a CDS.

Thus, we need to find a way to ensure the linearization, or correct ordering, of access procedures. 

For example, when and how will we guarantee that one access procedure completes before another one is started? The how is simple: we can sequentially order our access procedures i.e. apply a total ordering to all access procedures across our system. 

But that can be accomplished by using only a single process without the necessity for concurrent processes. Thus we need to address the \textit{when} of ordering access procedures using multiple concurrent processes.

Not all access procedures will need to be totally-ordered i.e. a complete (mathematical) linearization of our access procedures is not always a necessity. It is this \textit{lack of necessity of a total ordering} that allows us to have the possibility of concurrency in the first place. 

The degree to which our system can behave non-linearly is exactly the minimal degree to which it can be composed of concurrent processes. (Note: by "system" we are referring to a set of processes plus our CDS).

So, when is ordering a necessity? The only time two access procedures need an order is if one access procedure is \textit{dependent} on the other. We do not specify the reason for the dependency, but if a dependency exists (at all) then it is easy to see that an ordering is necessary.

Since the necessity for an ordering is not always required, we see that a complete linearization of our system is not always a necessity. Rather, the access procedures which carry a dependency on other access procedures create a \textit{partial ordering} for our system.

More specifically: all of our dependencies allows us to have a (disjoint )\textit{dependency graph} for our access procedures.

All good, right?! Sort of. Sadly, this does not resolve all of our problems. We have not discussed exactly how we will order access procedures in terms of processes.

\subsection{Spatial Dependencies}

First, let's diverge quickly back into a discussion of our CDS. Let's try to formalize it:

\begin{con-def}[Concurrent Data Structure (2)]
	\label{cds-graph}
	A \textit{concurrent data structure} is a graph $\mathcal{G} = \{\mathsf{N}, \mathsf{E}\}$ composed of $|\mathsf{N}|$ nodes and $|\mathsf{E}|$ edges, that is used to index data of type $\mathcal{T}$, and is allowed to be accessed by some set of processes $\mathcal{P}_{i}$ via some set of access types $\mathcal{A}_{t}$.
\end{con-def}

This helps us to remember that a data structure is a spatial object. It carries a certain topology and is invariant through time unless modified. Thus, it is completely possible that while access procedures may not carry a dependency: nodes of our CDS just might! The set of all nodular-dependencies will be called the: \textit{set of spatial dependencies}. These dependencies may be the dependencies that an access procedure ``adopts'' in order to consider itself dependent on another access procedure.

For example: if access procedure $\mathit{A}$ is trying to write to node $\mathrm{n}_{1} \in \mathsf{N}$ and access procedure $\mathit{B}$ is trying to write to node $\mathrm{n}_{2} \in \mathsf{N}$, but $\mathrm{n}_{2} < \mathrm{n}_{1}$ (where $<$ is a dependency arrow), then we would want to perform $\mathit{B}$ before $\mathit{A}$.

This set of spatial dependencies only covers the dependency relationships between certain nodes in our graph. But what if we wanted sub-graphs of our CDS to be dependent or more importantly \textit{independent} of other sub-graphs of our CDS?

Let's define this:

\begin{con-def}[Unique-Independent]
	\label{independents}
	Any sub-graph $\mathcal{S} \subseteq \mathcal{G}$ that does not contain any internal spatial dependencies is called an \textit{unique-independent} of our CDS.
\end{con-def}

Unique-Independents (UIs) can almost be seen as a \textit{virtualization} of our CDS's spatial topology.

Unique-Independents can obviously have external dependencies i.e. be dependent on each other. Thus, the set of UIs of our CDS forms a dependency graph. More specifically

\begin{con-def}[Disjoint Directed Acyclic Graph]
	\label{ddag}
	The set of UIs and their dependencies on one another forms a disjointed directed-acyclic graph i.e. a disjoint dependencies graph. It is disjointed since UIs are not required to have dependency relations with one another and thus some UIs (nodes) will not have edges in the graph.
\end{con-def}


Although, since UIs do not have to have other UIs as dependencies it will be simpler to consider a: dependencies list.

\begin{con-def}[Dependency List]
	\label{dependency-list}
	A \textit{dependencies list} for a CDS is the adjacency list of our disjointed graph of unique-independents.
\end{con-def}

\if
For any algebraist reading this: our dependencies list can almost be considered an \textit{anti-group} since inverses of ordered pairs \textit{cannot} exist in our list. An identity element cannot exist as the composition of any two objects cannot return to itself as that implies a cyclic dependency. Associativity and closure can exist for a basic composition operation, but objects in our dependency list can only be composed functionally (i.e. the last element of the ordered pair must be the first element of the ordered pair it is being composed with) -- so this composition only applies to a subset of our dependencies list. Thus, our dependencies list really becomes a sort of quasi-antithesis to a group.
\fi

Don't let the name ``unique-independent'' fool you. There is no requirement for an independent to be spatially-unique. In other words, a UI can share nodes from the CDS with other UIs. The only thing that makes a unique-independent ``unique'' is that it is in totality unique as to the nodes it applies too. 

So while, a UI can be completely subsumed by another UIs spatially, it will never refer to the exact same set of nodes that another UI is referring too. And it is this notion of ``uniqueness'' that allows it to be an independent.

This may seem like a unique-independent that subsumes UIs with dependencies that are other subsumed UIs conflicts with our definition (\ref{independents}) of an unique-independent. 

However, what we have to notice is that a unique-independent is evaluated separately from other UIs i.e. a UI that subsumes other UIs and their dependencies is only allowed to be addressed after all those other UIs have been addressed.

So, while an independent has ``no spatial dependencies'' it can still subsume UI-dependencies. 

One of the most important points to take away from this section is the fact that: the structure of the CDS itself has zero semblance of how we design our concurrent accesses, only the structure of our UI-DDAG (disjoint directed acyclic graph) does.

Now that we have a way to virtualize a CDS using UIs (in a spatial manner), let's tie UIs back in with our previous discussion about ordering access procedures.

We can now use the UI (spatial) virtualization of our CDS to assign an access procedure to a particular UI. We can provide a brief pseudo-code description (written in the Go programming language syntax).

\begin{minted}{go}
type AccessProcedure struct{
	A AccessType
	UID int // unique-independent id
}
\end{minted}

\subsection{Temporal Dependencies}

Since our dependency list of UIs based off this virtualization represents all possible spatial dependencies in our CDS it can be used to help us apply an ordering to access procedures. However, a spatial dependency is not the only way access procedures can be ordered i.e. be dependent on each other. The other way access procedures can have an ordering is: \textit{per UI}.

In other words, we can still order all access procedures that have been assigned to the same UI. For example, will read access procedures always take precedence over write access procedures for a particular UI? What if we wanted to be more specific (fine-grained) than that and give \textit{certain} access procedures precedence over \textit{certain} write access procedures?

It would be impossible to suggest that access procedures that apply to a specific UI could always be totally-ordered. Thus, we arrive at the same situation we were in before with trying to linearize our system. Thankfully, we have the answer: a dependency graph (list). Except, this time our dependencies list are access procedures assigned to the same UI. 

Whereas we had an UIs dependency list that represented a virtualization of the spatial dependencies, we now have a procedures dependency list that virtualizes the temporal dependencies of our CDS (per UI). Every UI will have it's own temporal dependencies list and every node in this disjoint dependencies graph will be a specific access procedure.

In this way we can redefine our access procedure code from above to include a temporal ddag node assignment:

\begin{minted}{go}
type AccessProcedure struct{
	A AccessType
	UID int // unique-independent id
	TID int // temporal ddag node id
}
\end{minted}

\subsection{Atomicity}

We still have to come back around to combining our ordering of dependencies with the processes in our system. But, first we should consider when two access procedures can be simply sequentially ordered. If some set of access procedures which apply to the same UI must be linearly ordered then we can consider the sequential composition of those procedures as being a new access procedure.

This can technically also apply to any sequence of access procedures (assigned to the same UI) that are not dependent on one another. If we want to reduce the total number of individual procedures in our system (i.e. reduce the number of nodes in our temporal dependency graph for a UI) then we can combine access procedures that are linearly dependent (or entirely independent) into a single access procedure.

The allowance for this combination is what we call: \textit{atomicity}.

\begin{con-def}[Atomic Procedures]
	\label{atomic-procedures}
	Any access procedure or sequence of access procedures that appear to the rest of the system as a single operation on a UI are called: \textit{atomic procedures}.
\end{con-def}

All access procedures \textit{should already be} atomic procedures. But, arbitrary sequences of procedures are not necessarily demanded to atomic. We want to specifically classify sequences of access procedures that \textit{are} atomic.

\begin{con-def}[Thread]
	\label{thread}
	A \textit{thread} is any sequence of access procedures that can be classified as a single atomic procedure. A thread can also be a  sequence of atomic procedures (which may be sequences of access procedures in of themselves).
\end{con-def}

In terms of a dependency graph: a thread is assigned to a node and is also assigned to the node's dependencies iff the dependent node has only one dependency \textit{and} the dependency has only one dependent. Any sequence of nodes each with at most one dependency and one dependent can be "combined" and considered: a single Thread.

Using threads makes our virtualization complexes more succinct, as any and all sequences of access procedures are either necessarily ordered or are considered single atomic procedures. It also becomes that every node in our disjoint dependency graphs are now a thread.

\begin{props}[Nodes are Threads]
	\label{nodes-are-threads}
	Every node in our disjoint temporal dependency graphs is a thread (iff we maintain that all access procedures must be atomic procedures).
\end{props}

\begin{con-cor}[Thread DDAG]
	\label{thread-ddag}
	For every disjoint dependency graph (a disjoint directed acyclic graph i.e. DDAG) of access procedures there is an equivalent disjoint dependency graph of threads.
\end{con-cor}

The fact of the matter is that the total number of UIs determines the minimum number of threads required to allow our CDS system to not be missing concurrency improvements (but is usually used when a maximum number of threads is a requirement).

If we choose to use a lesser amount of threads than we have UIs, then each thread will likely be assigned to multiple UIs? Can our system still offer a degree of undesired behavior avoidance in this case? The answer is yes, but that the management of behavior becomes internal to each thread.

In this case the threads will need to have internal sequential consistency. In other words, the ordering of dependent operations will only be based on the sequential ordering of access procedures within the thread. So, the thread should be well-ordered according to access procedures that apply to first: UI dependencies then UI dependents.

If the UIs that a thread is assigned to have no dependency relationship with each other (even composed dependency arrows) then the thread will not need to be ordered internally. Sometimes, ensuring this simple property makes the concurrency of the system simpler to implement and verify.

In the next section of this paper we will discuss how we will ensure atomicity for access procedures. But, for now, we simply hold this assumption as a given precondition.

\subsection{Dynamic Dependencies}

Now that we have methods for defining both spatial and temporal dependencies in our system, the question arises: what happens if a dependency has a lifecycle? What if a dependency needs to only hold true some of the time?

To solve these dynamic situations we can introduce the idea of a \textit{Virtual Dependency Graph} (VDG) which is a dependency graph that can apply to multiple UIs. The key is that is \textit{must} have a limited lifespan. If it does not have a limited lifespan then it just becomes another spatial or temporal DDAG.

\begin{con-def}[Virtual DDAG]
	\label{virtual-ddag}
	A dependency disjoint directed acyclic graph that can apply to one or more UIs for our CDS, but whose lifespan must be less than the lifespan of the CDS (system). Used to define dynamic dependencies in a concurrent system.
\end{con-def}

A VDG will always have a root node that connects to each UI that the VDG involves. This root node represents the final atomic procedure that the VDG will finish before completing its lifecycle.

For example, what if a particular write on one UI needed to happen before a different write on another UI, but that this was \textit{not} necessarily true for \textit{all} writes for these two UIs?

The final write would be the VDG's root node, and the dependency write would be a single child node to the root node. This also means that the two nodes could be a single thread that sequentially ordered a write to the first UI then a write to the second.

So, VDGs can be assigned to a single UI or too multiple UIs.

But, \textit{why} exactly must a VDG always have a limited lifespan (relative to the lifecycle of the system)? 

Well, in our previous mentioned example, if that VDG that applied to two UIs lasted forever then it would be no different than a spatial dependency (since it would signify that all writes for the dependent UI must wait on all writes for the dependency UI). If the VDG had only applied to a single UI then it would become a permanent temporal DDAG for similar reasons. The only thing that makes a VDG dynamic is the fact that it's lifespan is always less then that of the CDS.

Similar to the discussion in the Atomicity subsection on assigning the same thread to multiple UIs, assigning a thread to multiple V-DDAGs can possibly lead to an underutilized concurrency potential. Threads that are assigned to V-DDAGs are essentially virtual themselves, as it is their lifecycle that is the lifecycle of a node in a V-DDAG.

The final dynamic property of a system we want to briefly discuss is the idea of a: dynamic UI.

If UIs are allowed a lifecycle shorter than the system then the UI dependency graph could potentially need to be constantly redrawn. The only way to outright avoid this scenario is to create another entity that would behave like the nodes in a V-DDAG (and that we specify must have a lifespan less than that of the CDS).

If a UI were to be dynamic, but have dependencies, there would have to be a way to say that it could not end its lifecycle until its dependencies ended their lifecycles.

Actually, this leads us to a very important (not yet discussed) issue: UIs must cover all nodes in the CDS i.e. every node in the CDS must be addressed by at least one UI at all times. 

So, if we have dynamic UIs then we would have to check that before a UI could end its lifecycle that ever CDS node that it addresses must be addressed by some other UI. Seeing as this is just computationally inefficient, we thus note that dynamic UIs are only feasible if we create the secondary notion of: \textit{Virtual UIs}.

This allows us to have: \textit{Virtual UI dependency graphs}. But, then this also implies that every Virtual UI (VUI) could potentially have a V-DDAG attached to it (that must have a lifecycle less than or equal to the VUI node itself). All VUIs must have a lifecycle less than or equal to the VUI they are dependencies of. VUIs can apply to any set of nodes, but they must either have at least one real or one virtual dependent.

Every V-DDAG and VUI node is a thread that must make it's dependents aware of its existence. In fact, all nodes in any dependency graph (virtual or real) are just threads. The only difference is that real thread nodes do not control declaring themselves dependencies of one another, only virtual thread nodes can declare themselves as a (temporary) dependency of other thread nodes.

The final thing we would like to mention in this dependencies section is the fact that virtual (dynamic) nodes can still have real nodes (spatial and temporal) as their dependencies.

\subsection{Invariance}

The final part of discussing disjoint directed acyclic graphs and their equivalent dependencies lists is determining if an access type is allowed or not allowed to be used on a specific UI (or even at a specific time).

Boundary Nodes on our UI dependency graph can be useful for determining what access types are allowed for a UI. For example, it might be simpler to allow CDS-structure modifying access types for boundary UI nodes only: specifically appending and pruning sub-graphs to the CDS. 

But, we should first formalize what boundary nodes are and then look at an example of how this can be useful.

\begin{con-def}[Leaf Boundaries]
	\label{leaf-boundaries}
	Any real DDAG node which has no dependencies is considered a \textit{leaf boundary} node on that DDAG.
\end{con-def}

Every real (spatial and temporal) node can be represented by 4 numbers: spatial dependents, temporal dependents, spatial dependencies, and temporal dependencies.

\begin{minted}{go}
type RealNode struct{
	SpatialDependents uint
	TemporalDependents uint
	SpatialDependencies uint
	TemporalDependencies uint
}
\end{minted}

The basic difference between leaf-boundary and non-boundary real nodes can be expressed with these four variables succinctly:

\begin{itemize}
	\item Spatial Nodes: \{w, x, y, 0\}
	\item Spatial Leaf Boundary Nodes: \{0, x, y, 0\}
	\item Temporal Nodes: \{0, x, y, z\}
	\item Temporal Leaf Boundary Nodes: \{0, 0, y, z\}
\end{itemize}

There is another kind of boundary node for real DDAGs:

\begin{con-def}[Root Boundaries]
	\label{root-boundaries}
	Any real DDAG node which may or may not have dependencies but does not have any dependents is considered a \textit{root boundary} node on that DDAG.
\end{con-def}

The classes for root boundaries can be expressed using our primary 4 variables succinctly as well:

\begin{itemize}
	\item Spatial Root Boundary Nodes: \{0, 0, y, z\}
\end{itemize}

Notice, that we do not have Temporal Root Boundary Nodes defined. This is because of the following corollary.

\begin{con-cor}[No Temporal Root Boundaries]
	\label{no-temp-root-bounds}
	There are no Temporal root boundaries as every Temporal node must have at least one Spatial node dependency.
\end{con-cor}

\begin{con-ex} [2-Regular Tree]
	\label{2-regular-tree}
	We will consider a 3 node 2-Regular Tree for which we assign one node to a UI and make the root node's UI dependent on the the two leaf nodes UIs. This makes our UI DDAG have one root-boundary and two leaf-boundary nodes.

\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=3cm,
                   main node/.style={circle,draw,font=\small}]

  \node[main node] (1) {root};
  \node[main node] (2) [below left of=1] {leaf-1};
  \node[main node] (3) [below right of=1] {leaf-2};

  \path[every node/.style={}]
    (1) edge node [left] {} (2)
        edge node [right] {} (3);
\end{tikzpicture}

In this case, we will allow structure appending access types on the two leaf nodes. Specifically, we would like to ensure that these two UI nodes can only create new nodes on our 2-regular tree for each of the two branches of the tree (so that each UI has control over its own half of the 2-Regular Tree).

Thus, we can help ensure that the tree remains 2-Regular by not giving the root boundary UI node any append sub-graph access type rights.
\end{con-ex}

In Example \ref{2-regular-tree}, we see that modifying the structure of our tree is dependent on what we want to preserve (which in this case is a 2-Regular Tree structure). Thus, we did not allow the root boundary UI with it's dependencies to have the ability to use access types that modify our CDS structure (as there was no need for it too).

We divided the tree into 3 UIs which established an easy way to divide access procedures as well. However, we still would not want any of our 3 original CDS nodes to be deleted, \textit{yet} simulataneously we do want to be able to remove CDS nodes that have been appended to the two leaf CDS nodes if we want too. Therefore we still need a way to more precisely determine access type allowances.

Afterall, the above example is a very simple example. What would happen if we wanted to apply access rules for an arbitrary CDS graph structure or a more complex UI DDAG? As we have seen: one way to define a rule is by defining what is we want to preserve (at a given time) and what is allowed to change.

For example, we did want the original three CDS nodes in Example \ref{2-regular-tree} to be deleted. But, we could have if we wanted too.

In fact, each UI could have been assigned a list of \textit{immutable} CDS sub-graphs that cannot be removed or even have their values modified. More specifically, we could have had a list of sub-graphs in the CDS that are \textit{invariant} to certain access types.

\begin{con-def}[Invariants]
	\label{invariants}
	Any data $\mathsf{d}$ stored in our CDS, or any subgraph $\mathsf{S} \subset \mathsf{G}$ that does not change when acted upon by a specific Access Type $\mathcal{A}_{t}$ is called an invariant of that access type.
	\[ \mathcal{A}_{t}\mathsf{(d)} \rightarrow \mathsf{d} \]
	\[ \mathcal{A}_{t}\mathsf{(S)} \rightarrow \mathsf{S} \]
\end{con-def}

\begin{con-aside}
Immutability is only a kind of invariance. A low-resolution invariance which blanket-denies all modification access types.
\end{con-aside}

Every node in our CDS Graph $\mathsf{G}$ has a set of access types $\mathcal{A}$ that it is invariant under. Either the CDS node and its value remain invariant under an access type (e.g. a ``read'' or "copy" access type), or only the node itself remains invariant (e.g. a ``write'' or "increment" access type). Otherwise, the node and the value are mutable (e.g. in a ``delete-subgraph'' access type).

Thus, these are the canonical invariance classes for access types:

\begin{itemize}
	\item Node and Value are invariant
	\item Node is invariant
	\item No Invariance 
\end{itemize}

We could of course describe invariants at a higher level e.g. in terms of sub-graphs which are or not invariant under an access type. But, for now we just leave this as a pattern that can be used to help determine access types that are allowed (or not allowed) to be used by a particular process accessing the CDS.


\subsection{Partial Orderings}

The last thing we want to mention about DDAGs is rules for how the DDAG structure should be organized. One approach is by defining a partial ordering for the nodes that will be in the DDAG. We will not expound completely on this topic in this paper, instead only mention a single possible approach to temporal DDAGs.

We want to discuss \textit{access type priorities} and how they can be used to define an ordering on a temporal DDAG. We know that access types can be simple reads and writes to much more complex calculation-based overwrites. However, 

FINISH THIS SECTION


\subsection{Review}

\begin{con-def}[Spatial Threads]
	\label{spatial-threads}
	\textit{Spatial Threads} are threads that last the lifespan of the CDS and are attached to a single UI.
\end{con-def}

\begin{con-def}[Temporal Threads]
	\label{temporal-threads}
	\textit{Temporal Threads} are threads that last the lifespan of the CDS and are attached to a single UI (in this case temporal threads represent all (permanent) threads beyond the initial spatial thread attached to a UI).
\end{con-def}

\begin{con-def}[Virtual Threads]
	\label{virtual-threads}
	\textit{Virtual Threads} are threads that have a lifespan shorter than the CDS (or "Thread Node" that they are a dependency of) and can be assigned to multiple UIs.
\end{con-def}