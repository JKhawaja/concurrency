\section{Introduction}

In this paper we would like to describe an algorithmic approach to avoiding undesirable behavior that arises in systems with multiple processes (threads) accessing a shared data structure. We should first supply a basic definition for a concurrent data structure.

\begin{con-def}[Concurrent Data Structure]
	\label{cds}
	A \textit{concurrent data structure} is a data structure that is concurrently accessed by multiple processes. The processes are allowed to read and write data as well as modify the structure itself.
\end{con-def}

There aready exist a plethora of approaches to managing access to a shared structure, of which we will make brief mention of only a few techiques e.g. \textit{locks}, \textit{fine-grained locking}, \textit{combining trees}, etc.

For example, here is a basic definition of locking a data structure.

\begin{con-def}[Locking]
	\label{locks}
	A \textit{lock} is a device that enforces a temporary operation ownership of the concurrent data structure by a process e.g. a process in posession of the write lock will be the only process allowed to write data to the structure. Using a set of locks where each lock applies to only a substructure of the overall data structure is called: \textit{fine-grain locking}.
\end{con-def}

In most programming languages a lock is called a \textit{mutex} (mutual exclusion).

It is also important to specify what exactly we mean by \textit{undesirable behavior}.

\begin{con-def}[Undesired Behavior]
	\label{ub}
	The primary potential behaviors we will be focused on avoiding in this paper are: redundancy, data races, access blocking, and a lack of any consistency guarantee.
\end{con-def}

For example, some of the potential behavioral problems with locks can vary from things like taking too many locks or too few locks, to taking the wrong locks or taking locks in the wrong order.

Essentially we are trying to avoid problems with inefficiency and inconsistency. Namely, we would like to avoid overwriting values that have already been written. And we would also like to avoid problems that are usually seen as a lack of linearization e.g. a value being overwritten with an out-of-date value.

Of course, every access management implementation will require a degree of tradeoff. For example, are we allowed to read a value from our concurrent data structure at any time or must we always guarantee that all currently-in-progress writes have been completed? We will not focus on tradeoff choices in this paper. How a developer may choose to utilize the algorithm in this paper will depend on the developers personal choice of system requirements. But we do note that the algorithm will be rather flexible in varying the degree of consistency for concurrently accessing a structure.

One of the usual goals of concurrently accessing a single data structure is: computation efficiency i.e. speedup. Sometimes it is also used to avoid having multiple copies of the same structure and being forced to use a consensus algorithm to determine which one has the ``true state'' of the structure (or a sub-structure) at a given moment in time.

These goals/reasons for concurrent data structure design will not be the focus of this paper. Instead, we will focus on devising an (astoudingly rather simple) algorithm that will be able to 'monitor' and maintain the state of an arbitrary concurrent data structure for us to a degree of consistency that we would like it to have.




